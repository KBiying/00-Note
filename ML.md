1. 为什么要分测试集、训练集、验证集

   泛化能力：测试集和训练集training set and testing set

   调参：验证集 validation set -> 训练集训练，验证集看结果，调参，再看验证机结果，参数调完，最后在测试集上看结果。

2. K折交叉验证：将数据集分为K份，每次抽取其中1份做测试集，进行K次。最终将K个结果取平均。缺点是当数据量较大时，对算力的要求较高。

3. 泛化能力：模型的预测能力。

   # 维数约减

   ## 特征选择

   目标：保留用于学习的相关特征并去除冗余和不相关的特征，从而让模型发挥更好的性能。

   ### 过滤式方法：

   先对数据集进行特征选择，然后再训练学习器，特征选择过程与后续学习过程相互独立

   思路：打分，赋权重，按权重排序

   主要方法：相关系数，卡方验证，信息增益/互信息

   ### 包裹式方法：

   ### 嵌入式方法：

   正则化，决策树

   

   ## 特征

   ## 无监督降维

   PCA思想：重构坐标轴，使样本点尽可能离散地投影到新的坐标轴上

   缺点是容易受到离群点的影响

   ## 有监督降维

   PCA和LDA比较

   - 相似点，pca和lda有很大的相似性，最后其实都是求某一个矩阵的特征值，投影矩阵即为该特征值对应的特征向量
   - 差异
     - pca为非监督降维， lda有监督降维
     - PCA希望投影后的数据方差尽可能的大（最大可分性），因为其假设方差越大，则所包含的信息越多；而LDA则希望投影后相同类别的足内方差小，而组间方差大。LDA能合理运用标签信息，是的投影后的维度具有判别性，不同类别的数据尽可能地分开
     - 有标签就尽量使用标签的数据，而对于纯粹的非监督任务，则还是得用PCA进行数据降维。

## 决策树

经典分类算法 

C4.5

CART







