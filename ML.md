1. 为什么要分测试集、训练集、验证集

   泛化能力：测试集和训练集training set and testing set

   调参：验证集 validation set -> 训练集训练，验证集看结果，调参，再看验证机结果，参数调完，最后在测试集上看结果。

2. K折交叉验证：将数据集分为K份，每次抽取其中1份做测试集，进行K次。最终将K个结果取平均。缺点是当数据量较大时，对算力的要求较高。

3. 泛化能力：模型的预测能力。

   # 维数约减

   ### 特征选择

   目标：保留用于学习的相关特征并去除冗余和不相关的特征，从而让模型发挥更好的性能。

   #### 过滤式方法：

   先对数据集进行特征选择，然后再训练学习器，特征选择过程与后续学习过程相互独立

   思路：打分，赋权重，按权重排序

   主要方法：相关系数，卡方验证，信息增益/互信息

   #### 包裹式方法：

   #### 嵌入式方法：

   正则化，决策树

   

   ### 特征

   ### 无监督降维

   PCA思想：重构坐标轴，使样本点尽可能离散地投影到新的坐标轴上

   缺点是容易受到离群点的影响

   ### 有监督降维

   PCA和LDA比较

   - 相似点，pca和lda有很大的相似性，最后其实都是求某一个矩阵的特征值，投影矩阵即为该特征值对应的特征向量
   - 差异
     - pca为非监督降维， lda有监督降维
     - PCA希望投影后的数据方差尽可能的大（最大可分性），因为其假设方差越大，则所包含的信息越多；而LDA则希望投影后相同类别的足内方差小，而组间方差大。LDA能合理运用标签信息，是的投影后的维度具有判别性，不同类别的数据尽可能地分开
     - 有标签就尽量使用标签的数据，而对于纯粹的非监督任务，则还是得用PCA进行数据降维。

# 决策树

### 概述

决策：指决定的策略或办法，是人们为各种事件出主意，做决定的过程。是一个复杂的思维操作过程，是信息搜索加工最后做出判得出结论的过程

决策树组成：决策节点、分支、叶子

### CLS算法

思想：选择属性，根据属性值划分子集；（分而治之）
原则：（1） 如果子集为空或属于同一类，为叶结点；
（2）否则，对应于内部结点，即测试结点；
（3）选择新属性进行划分，直至得到条件（1）
问题：没有指定选择属性原则，方法及先后顺序，而选择的顺序对学习比较有影响。

### ID3 C4.5算法

主要针对属性选择问题，使用**信息增益**选择测试属性

**信息熵的公式：**Ent(D) = 

信息熵越小纯度越高。

ID3基本思想：ID3以信息熵为度量，用于决策树节点的属性选择，每次优选信息量最多的属性（条件信息熵最小，信息增益最大），构造一个熵值下降最快的决策树，知道叶子结点处熵值为0.此时叶子结点对应实例为同一类

缺点:只能用于离散属性, 对于连续值处理, 离散化-二分法;不包含对树的修减,过拟合.

问题1：采用信息增益划分训练数据集时，偏向于选取取值较多的（n大的）特征或属性问题，但这些特征可能是无意义的特征，如用户ID，学号，日期等。如果选取值较多的特征，会使决策树分支过多。

解决(奥卡姆剃刀)：引入信息增益比，特征A对训练数据集D的信息增益比定义为：其信息增益g(D,A)与训练数据D关于特征A的值的熵HA(D)之比。公式G(D,A) = 

HA(D)可看作是岁信息增益的惩罚，特征A取值越多，HA(D)就越大。 

### CART决策树

pass

### 决策树剪枝

预剪枝后剪枝

### 习题

如何决策出好瓜坏瓜

西瓜数据集合计算

# 感知机

### 目标:

寻找一个超平面使得不同类别的样本点能完全正确的分离开

#### 表达式:

​	正确\错误分类条件:

#### 优化目标:

使误分类的所有样本到超平面的距离之和最小

#### 算法:

输入:

输出:

1.初始化参数(w0, b0)

2.选取数据点(xi,yi)

3.如果当前点为误分点,即值小于0,则更新参数

4.迭代至没有误分点

# SVM

### 硬间隔及优化目标函数

### 软间隔与正则化目标函数

### 核方法目标函数

# 贝叶斯

### 贝叶斯理论

联合分布,边缘分布,条件概率

独立,链式规则

贝叶斯规则公式:

贝叶斯推理:先画决策树,再计算P(A),P(B),P(A|B); 再根据公式P(B|A)

### 朴素贝叶斯分类器

拉普拉斯修正,加一处理

### 贝叶斯网络

三变量之间的关系

# kaggle房价预测

1.官方给出的数据包含训练数据和测试数据

2.评价指标：回归中常用到的均方误差（rmse）。公式 = 

3.数据处理：

> 先查看数据集
>
> 测试集中，id与房价无关，去掉
>
> 目标值分析：目标值的分布、其他特征与目标值的关系
>
> trick：将类别特征和数值特征分离开，在处理时会比较方便
>
> 查看目标值与数字特征的关系，可以找出某些特征值与目标值有明显的线性关系，对目标值预测应该很大，因此这是我们的重点对象特征。
>
> 取与目标值相关度最高的十个特征再次绘制相关度热图， 并绘制这十个特征两两之间的散点图
>
> 可以看出房子所在区域，邻居，totalsf是是重点关注特征

- 处理异常值：删除掉明显的离群点
- 处理缺失值：删除掉基本上全都为同一值的特征，这类特征对预测基本不起作用；对缺失值补充该特征出现次数最多的值；对于可能为零的特征值，缺失值全部补零；对不为零的特征，取中位数。
- 转换类别编码：对于各个类别中可能存在顺序关系的用LabelEncoder编码，对于不存在顺序关系的，用get_dummies

4.模型预测

- 读取数据，处理目标值。对目标值取对数，将其处理成正态分布
- 定义交叉验证策略以及评估方法：由于训练集的数据较少，所以采用十折交叉验证。
- 采用回归常用的两个模型：ridge，Gradientboosting。
- 反复调参

5.模型评估

- 均方误差

